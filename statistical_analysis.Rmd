---
title: "Statistical Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
---

#Statistical Analysis

```{r}
library(MASS)
library(tidyverse)
```

## Dataset Preparation
```{r}
tidy_df = 
  read.csv(
    "data/significant-volcanic-eruption-database.csv", 
    sep = ";", na.strings=c("", NA)) |>
  janitor::clean_names() |>
  select(
    -c(month, day, location, status, volcano_missing, volcano_missing_description, earthquakes_houses_damaged_description),
    -starts_with("total")
    ) |>
  mutate( # change flags to boolean
    flag_tsunami = case_match(flag_tsunami, "Tsunami"~ TRUE, NA ~ FALSE),
    flag_earthquake = case_match(flag_earthquake, "Earthquake"~ TRUE, NA ~ FALSE)
  ) |>
  separate(coordinates, into = c("lat", "long"), sep = ",") |>
  mutate(
    lat = as.numeric(lat), long = as.numeric(long)
  ) |>
  mutate_at(vars(ends_with('description')), ~ifelse(is.na(.), "None/No Record", .)) |>
  mutate( # shorten description
    volcano_deaths_description = case_match(
      volcano_deaths_description,
      "Very Many (~1001 or more deaths)" ~ "Very Many (~1001 or more)", 
      "Many (~101 to 1000 deaths)" ~ "Many (~101 to 1000)", 
      "Some (~51 to 100 deaths)" ~ "Some (~51 to 100)", 
      "Few (~1 to 50 deaths)" ~ "Few (~1 to 50)",
      "None/No Record" ~ "None/No Record"
    ),
    volcano_injuries_description = case_match(
      volcano_injuries_description,
      "Very Many (~1001 or more deaths)" ~ "Very Many (~1001 or more)", 
      "Many (~101 to 1000 deaths)" ~ "Many (~101 to 1000)", 
      "Some (~51 to 100 deaths)" ~ "Some (~51 to 100)", 
      "Few (~1 to 50 deaths)" ~ "Few (~1 to 50)",
      "None/No Record" ~ "None/No Record"
    ),
    volcano_damage_description = case_match(
      volcano_damage_description,
      "EXTREME (~$25 million or more)" ~ "EXTREME (~>=$25 million)", 
      "SEVERE (~>$5 to $24 million)" ~ "SEVERE (~$5 to $24 million)", 
      "MODERATE (~$1 to $5 million)" ~ "MODERATE (~$1 to $5 million)", 
      "LIMITED (roughly corresponding to less than $1 million)" ~ "LIMITED (~<$1 million)",
      "None/No Record" ~ "None/No Record"
    ),
    volcano_houses_destroyed_description = case_match(
      volcano_houses_destroyed_description,
      "Very Many (~1001 or more houses)" ~ "Very Many (~1001 or more)", 
      "Many (~101 to 1000 houses)" ~ "Many (~101 to 1000)", 
      "Some (~51 to 100 houses)" ~ "Some (~51 to 100)", 
      "Few (~1 to 50 houses)" ~ "Few (~1 to 50)",
      "None/No Record" ~ "None/No Record"
    )
  ) |>
  mutate( # change descriptions to factors w/ levels
    volcano_deaths_description = factor(volcano_deaths_description, levels = c("Very Many (~1001 or more)", "Many (~101 to 1000)", "Some (~51 to 100)", "Few (~1 to 50)", "None/No Record")),
    volcano_injuries_description = factor(volcano_injuries_description, levels = c("Very Many (~1001 or more)", "Many (~101 to 1000)", "Some (~51 to 100)", "Few (~1 to 50)", "None/No Record")),
    volcano_damage_description = factor(volcano_damage_description, levels = c("EXTREME (~>=$25 million)", "SEVERE (~$5 to $24 million)", "MODERATE (~$1 to $5 million)", "LIMITED (~<$1 million)", "None/No Record")),
    volcano_houses_destroyed_description = factor(volcano_houses_destroyed_description, levels = c("Very Many (~1001 or more)", "Many (~101 to 1000)", "Some (~51 to 100)", "Few (~1 to 50)", "None/No Record"))
  )

```

## Ordered logistic regression

### Methodology



### Correlation analysis(相关性分析)

```{r}
library(Hmisc)
library(corrplot)

variables_of_interest <- c("flag_earthquake", "flag_tsunami", "volcanic_explosivity_index", "elevation")

selected_data <- tidy_df %>%
  select(all_of(variables_of_interest))

cor_matrix <- rcorr(as.matrix(selected_data), type = "spearman")

correlation_matrix <- cor_matrix$r
p_value_matrix <- cor_matrix$P
p_value_matrix[is.na(p_value_matrix)] <- 1
corrplot(correlation_matrix, p.mat = p_value_matrix, method = "color",
         tl.col = "black", tl.srt = 45, tl.offset = 0.5, tl.cex = 0.8,
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, pch.col = "grey20",
         tl.pos = "lt", insig = "label_sig", type = "upper")
corrplot(correlation_matrix, type = "lower", add = TRUE, method = "number",
         tl.pos = "n", cl.pos = "n")
```

### Test effect modifier
Now we will examine the relationship between the dependent variable `volcano_deaths_description` and the interaction between `flag_earthquake` and `flag_tsunami`.
```{r}
model1 <- polr(volcano_deaths_description~flag_earthquake*flag_tsunami,data = tidy_df)
summary(model1)

ctable1 <- coef(summary(model1))

p <- pnorm(abs(ctable1[, "t value"]), lower.tail = FALSE) * 2

(ctable1 <- cbind(ctable1, "p value" = p))

```
The interaction p-value is greater than 0.05, so it's not significant. There is not enough evidence to suggest that the relationship between volcano_deaths_description and the combination of flag_earthquake and flag_tsunami is significantly different from the sum of their individual effects.Given this result, we consider using a simpler model without the interaction term.

### Fit the Ordinal Logistic Regression Model

```{r}
model2 <- polr(volcano_deaths_description ~ flag_earthquake + flag_tsunami + volcanic_explosivity_index+elevation, data = tidy_df, Hess=TRUE)

## view a summary of the model
summary(model2)
```


### Comparison between models with and without flag_tsunami(相关性分析的后续，不需要的话就删掉)

```{r}
model_without_tsunami <- polr(volcano_deaths_description ~ flag_earthquake + volcanic_explosivity_index + elevation, data = tidy_df, Hess = TRUE)
anova(model2, model_without_tsunami)|> knitr::kable()
```

The estimated model can be written as:


Interpretation:



Some people require a p value to be satisfied. In this situation, comparing the t-value to the conventional normal distribution using a z test is one method of computing a p-value. This is only true when there are infinite degrees of freedom, but large samples can well approximate it; as sample size drops, the sample becomes more biased. This method is simple to implement and is utilized in other software programs like Stata. We compute the p-values and then merge them back with the table after storing the coefficient table.
```{r}
## store table
ctable2 <- coef(summary(model2))

## calculate and store p values
p <- pnorm(abs(ctable2[, "t value"]), lower.tail = FALSE) * 2

## combined table
(ctable2 <- cbind(ctable2, "p value" = p))
```
Interpretation:






We can also get confidence intervals for the parameter estimates.
```{r}
# default method gives profiled CIs
(ci <- confint(model2)) 

# CIs assuming normality
confint.default(model2) 
```
Interpretation:



Another way to interpret logistic regression models is to convert the coefficients into odds ratios. To get the OR and confidence intervals, we just exponentiate the estimates and confidence intervals.
```{r}
## odds ratios
exp(coef(model2))

## OR and CI
exp(cbind(OR = coef(model2), ci))

```
Interpretation:
