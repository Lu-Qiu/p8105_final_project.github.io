---
title: "Statistical Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: "hide"
---


```{r setup, include=FALSE}
library(MASS)
library(tidyverse)
library(Hmisc)
library(corrplot)

# set knitr defaults
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE
)

# set theme defaults
theme_set(theme_minimal() + theme(legend.position = "bottom"))

# set color scale defaults
options(
    ggplot2.continuous.colour = "viridis",
    ggplot2.continuous.fill   = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete   = scale_fill_viridis_d
```

## Methodology

Based on the results in exploratory data analysis, it is clear that deaths, injuries, damage and houses destroyed by volcanic eruptions can be affected by factors like earthquake, tsunami and VEI of the volcano. To better describe their relationship, in this part, we aim to fit an ordinal logistic regression model, utilizing the descriptive data of deaths, injuries, damage and houses destroyed as outcome.

.......
.......

## Correlation Analysis

First, we perform a correlation analysis. If two predictors have strong correlation, we can only keep one of them in our regression model. This careful consideration ensures the avoidance of multicollinearity, thereby enhancing the precision and interpretability of our model's results.

Correlation between the variables is shown by the following heatmap:
```{r}
# Import tidied data
tidy_df = read.csv2("data/volcanic-eruption-final.csv", sep = ",", stringsAsFactors = TRUE)

# Select variables of interest
selected_data <- 
  tidy_df |>
  dplyr::select(flag_earthquake, flag_tsunami, volcanic_explosivity_index, elevation)

cor_matrix <- rcorr(as.matrix(selected_data), type = "spearman")

correlation_matrix <- cor_matrix$r
p_value_matrix <- cor_matrix$P
p_value_matrix[is.na(p_value_matrix)] <- 1
corrplot(correlation_matrix, p.mat = p_value_matrix, method = "color",
         tl.col = "black", tl.srt = 45, tl.offset = 0.5, tl.cex = 0.8,
         sig.level = c(0.001, 0.01, 0.05), pch.cex = 0.9, pch.col = "grey20",
         tl.pos = "lt", insig = "label_sig", type = "upper")
corrplot(correlation_matrix, type = "lower", add = TRUE, method = "number",
         tl.pos = "n", cl.pos = "n")
```

From the results of correlation analysis, we can see that there is a positive correlation between `flag_tsunami` and `flag_earthquake`. However, correlation coefficient (r) is 0.35, indicating only a moderate correlation. Therefore, we'll include both `flag_tsunami` and `flag_earthquake` in our later analysis.   
We also notice that there is a negative correlation between `elevation` and `flag_tsunami`. This is probably because volcanoes under the sea are more likely to cause tsunami.


## Test of Effect Modifier
To test for the presence of an effect modifier, we'll use an interaction term in our regression model. An interaction term is the product of variables and is included in the model to examine whether the effect of one variable on the outcome is different depending on the level of the other variables.

```{r}
# Fit a model with interaction term
interaction_model <- polr(volcano_deaths_description ~ flag_earthquake*flag_tsunami*volcanic_explosivity_index, data = tidy_df)

# Tidy up the summary
tidy_interaction <- broom::tidy(interaction_model)

# Add p-values to the tidy summary
tidy_interaction$p_value <- pnorm(abs(tidy_interaction$estimate), lower.tail = FALSE) * 2

# Display the tidy summary
knitr::kable(tidy_interaction)
  

```

Because none of the interaction term is statistically significant (p-value > 0.05). There is not enough evidence of effect modification. Given this result, we consider using a simpler model without the interaction term.

## Fit the Ordinal Logistic Regression Model

```{r}
model2 <- polr(volcano_deaths_description ~ flag_earthquake + flag_tsunami + volcanic_explosivity_index + elevation, data = tidy_df, Hess=TRUE)

## view a summary of the model
summary(model2)
```


The estimated model can be written as:


Interpretation:



Some people require a p value to be satisfied. In this situation, comparing the t-value to the conventional normal distribution using a z test is one method of computing a p-value. This is only true when there are infinite degrees of freedom, but large samples can well approximate it; as sample size drops, the sample becomes more biased. This method is simple to implement and is utilized in other software programs like Stata. We compute the p-values and then merge them back with the table after storing the coefficient table.
```{r}
## store table
ctable2 <- coef(summary(model2))

## calculate and store p values
p <- pnorm(abs(ctable2[, "t value"]), lower.tail = FALSE) * 2

## combined table
(ctable2 <- cbind(ctable2, "p value" = p))
```
Interpretation:






We can also get confidence intervals for the parameter estimates.
```{r}
# default method gives profiled CIs
(ci <- confint(model2)) 

# CIs assuming normality
confint.default(model2) 
```
Interpretation:



Another way to interpret logistic regression models is to convert the coefficients into odds ratios. To get the OR and confidence intervals, we just exponentiate the estimates and confidence intervals.
```{r}
## odds ratios
exp(coef(model2))

## OR and CI
exp(cbind(OR = coef(model2), ci))

```
Interpretation:
